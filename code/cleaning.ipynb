{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7966d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import sys \n",
    "import config_options as cfg\n",
    "chosen_day = cfg.chosen_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ceaf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(dir, chosen_day):\n",
    "    day_fmt1 = chosen_day.replace(\"-\", \"\")   # YYYYMMDD\n",
    "    day_fmt2 = (chosen_day[:4] + \"-\" + chosen_day[4:6] + \"-\" + chosen_day[6:]) if \"-\" not in chosen_day else chosen_day\n",
    "    \n",
    "    files = [f for f in os.listdir(dir) if (day_fmt1 in f or day_fmt2 in f) and f.endswith(\".csv\")]\n",
    "    if files:\n",
    "        full_path = os.path.join(dir, files[0])\n",
    "        df = pd.read_csv(full_path)\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Dia {chosen_day} no encontrado en {dir}. Revisa en la carpeta\")\n",
    "        return None\n",
    "\n",
    "data_base_option = read_csv(cfg.dir_md_opciones, chosen_day)\n",
    "data_base_underlying = read_csv(cfg.dir_md_subyacente, chosen_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d272b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_option[\"biof_fecha\"] = pd.to_datetime(data_base_option[\"biof_fecha\"])\n",
    "data_base_underlying[\"biof_fecha\"] = pd.to_datetime(data_base_underlying[\"biof_fecha\"])\n",
    "\n",
    "def flujo_eventos(data_base_option: pd.DataFrame,\n",
    "                  data_base_underlying: pd.DataFrame,\n",
    "                  opt_cols,\n",
    "                  und_cols,\n",
    "                  time_col,\n",
    "                  id_col):\n",
    "    opt_cols = list(opt_cols)\n",
    "    und_cols = list(und_cols)\n",
    "\n",
    "    # Subyacente\n",
    "    und = (data_base_underlying\n",
    "           .sort_values(time_col)\n",
    "           [[time_col] + und_cols + [\"ultimo_fecha\"]]  # aseguro que esté ultimo_fecha\n",
    "           .rename(columns={c: f\"{c}_under\" for c in und_cols + [\"ultimo_fecha\"]})\n",
    "           .set_index(time_col))\n",
    "\n",
    "    und_suff = [f\"{c}_under\" for c in und_cols]\n",
    "    trade_col_und = \"ultimo_fecha_under\"\n",
    "\n",
    "    out = []\n",
    "    for opt_id, g in data_base_option.groupby(id_col, sort=False):\n",
    "        g = (g.sort_values(time_col)\n",
    "               [[time_col] + opt_cols + [\"ultimo_fecha\"]]  # aseguro ultimo_fecha\n",
    "               .set_index(time_col))\n",
    "\n",
    "        trade_col_opt = \"ultimo_fecha\"\n",
    "\n",
    "        t = und.index.union(g.index).unique().sort_values()\n",
    "\n",
    "        g_re = g.reindex(t).ffill()\n",
    "        u_re = und.reindex(t).ffill()\n",
    "\n",
    "        df = pd.concat([g_re, u_re], axis=1)\n",
    "\n",
    "        # cambios en order book\n",
    "        changed_opt = df[opt_cols].ne(df[opt_cols].shift()).any(axis=1)\n",
    "        changed_und = df[und_suff].ne(df[und_suff].shift()).any(axis=1)\n",
    "\n",
    "        changed_opt = changed_opt & df[opt_cols].notna().any(axis=1)\n",
    "        changed_und = changed_und & df[und_suff].notna().any(axis=1)\n",
    "\n",
    "        # cambios en trade (ultimo_fecha)\n",
    "        trade_opt = df[trade_col_opt].ne(df[trade_col_opt].shift())\n",
    "        trade_und = df[trade_col_und].ne(df[trade_col_und].shift())\n",
    "\n",
    "        if not df.empty:\n",
    "            changed_opt.iloc[0] = False\n",
    "            changed_und.iloc[0] = False\n",
    "            trade_opt.iloc[0] = False\n",
    "            trade_und.iloc[0] = False\n",
    "\n",
    "        block = df.reset_index().rename(columns={'index': time_col})\n",
    "        block[id_col] = opt_id\n",
    "        block['changed_opt'] = changed_opt.values\n",
    "        block['changed_und'] = changed_und.values\n",
    "        block['trade_opt'] = trade_opt.values\n",
    "        block['trade_und'] = trade_und.values\n",
    "\n",
    "        # Clasificación de eventos\n",
    "        event = np.full(len(block), \"NONE\", dtype=object)\n",
    "        # Prioridad: primero OB, luego trades\n",
    "        event[(changed_opt & changed_und)] = \"OB_BOTH\"\n",
    "        event[(changed_opt & ~changed_und)] = \"OB_OPT\"\n",
    "        event[(~changed_opt & changed_und)] = \"OB_UND\"\n",
    "        mask_no_ob = ~(changed_opt | changed_und)\n",
    "        event[(mask_no_ob) & (trade_opt & trade_und)] = \"TRADE_BOTH\"\n",
    "        event[(mask_no_ob) & (trade_opt & ~trade_und)] = \"TRADE_OPT\"\n",
    "        event[(mask_no_ob) & (~trade_opt & trade_und)] = \"TRADE_UND\"\n",
    "        block[\"event\"] = event\n",
    "        if not block.empty:\n",
    "            block.loc[block.index[0], \"event\"] = \"INIT\"\n",
    "\n",
    "        out.append(block)\n",
    "\n",
    "    result = (pd.concat(out, ignore_index=True)\n",
    "                .sort_values([id_col, time_col])\n",
    "                .reset_index(drop=True))\n",
    "    return result\n",
    "\n",
    "data_base_merged = flujo_eventos(\n",
    "     data_base_option,\n",
    "     data_base_underlying,\n",
    "     opt_cols=('bi_1_precio','bi_1_size','of_1_precio','of_1_size'),\n",
    "     und_cols=('bi_1_precio','bi_1_size','of_1_precio','of_1_size'),\n",
    "     time_col='biof_fecha',\n",
    "     id_col='id_simbolo' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b031d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_merged = data_base_merged[(data_base_merged[\"event\"]==\"OB_UND\")|(data_base_merged[\"event\"]==\"OB_OPT\")|(data_base_merged[\"event\"]==\"OB_BOTH\")]         #en caso de mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9334ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_merged[\"instrument\"] = data_base_merged[\"id_simbolo\"].str.extract(r\"GFG([CV])\")\n",
    "data_base_merged[\"instrument\"] = data_base_merged[\"instrument\"].map({\"C\": \"call\", \"V\": \"put\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a02fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_strike(id_simbolo, precio_under):\n",
    "    codigo = id_simbolo.split(\" - \")[2]\n",
    "    match = re.search(r'(\\d+)', codigo)\n",
    "    if match:\n",
    "        numero = int(match.group(1))\n",
    "        \n",
    "        # Regla 1: si termina en 3 -> dividir por 10\n",
    "        if str(numero).endswith(\"3\"):\n",
    "            strike = numero / 10\n",
    "        else:\n",
    "            strike = numero\n",
    "        \n",
    "        # Regla 2: si el strike es ~3 veces mayor al precio_under -> dividir por 10\n",
    "        if strike >= 3 * precio_under:\n",
    "            strike = strike / 10\n",
    "        \n",
    "        return strike\n",
    "    return None\n",
    "\n",
    "data_base_merged[\"strike\"] = data_base_merged.apply(\n",
    "    lambda row: extraer_strike(row[\"id_simbolo\"], row[\"of_1_precio_under\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae6b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_merged[\"intrinsic_value\"] = np.where(\n",
    "    data_base_merged[\"instrument\"].str.lower() == \"call\",\n",
    "    data_base_merged[\"bi_1_precio_under\"] - data_base_merged[\"strike\"],\n",
    "    data_base_merged[\"strike\"] - data_base_merged[\"of_1_precio_under\"]\n",
    ")\n",
    "data_base_merged[\"intrinsic_value\"] = data_base_merged[\"intrinsic_value\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e53e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_merged[\"time_value\"] = np.where(\n",
    "    (data_base_merged[\"of_1_precio\"].notna()) & (data_base_merged[\"of_1_precio\"] != 0),\n",
    "    data_base_merged[\"of_1_precio\"] - data_base_merged[\"intrinsic_value\"],\n",
    "    np.nan\n",
    ")\n",
    "data_base_merged = data_base_merged.dropna(subset=[\"time_value\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
